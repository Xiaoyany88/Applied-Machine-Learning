{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9eb60d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# Set preference to CUDA (GPU) if avail, fallback to CPU otherwise\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa122d5",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d18968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose of having seperate transformations for training and validation datasets is to introduce randomness and variability in training\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        # randomly crops input image to size of 224 x 224 pixels, helps model learn to recognize objs in diff scales and proportions\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        \n",
    "        # default prob of 0.5, learn from mirrored versions\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        \n",
    "        # rotate by random angle betwn -10 and 10 degrees\n",
    "        transforms.RandomRotation(10),\n",
    "        \n",
    "        # converts image into a PyTorch tensor, necessary as PyTorch models operate on tensors\n",
    "        transforms.ToTensor(),\n",
    "        \n",
    "        # normalizes the tensor image w a mean and std dev for each RGB, ensures input features similar scale. Specific values used are standard for models pre-trained on ImageNet dataset.\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        \n",
    "        # resize input image to 256 pixels on shorter side\n",
    "        transforms.Resize(256),\n",
    "        \n",
    "        # crops image to 224x224 pixels around cntre\n",
    "        transforms.CenterCrop(224),\n",
    "        \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2bf27d",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d72dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads image from a specified directory \n",
    "data_dir = 'a5_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0684b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary for training and validation. Uses ImageFolder class, assigns labels based on their subdirectory names. \n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "\n",
    "# load data into memory in batches, making it easier to manage memory usage and improve computation efficiency.\n",
    "# data will be loaded in batches of 4 in random order as data will be shuffled at every epoch, reduce overfitting\n",
    "# num_workers=4 allow parallel data loading, speeding up process\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# create dict to store no of imgs avail in training and validation datasets. Use for calculating accuracy or loss per epoch\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6891f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve list of class names from training dataset\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aff2ab",
   "metadata": {},
   "source": [
    "## Model Preparation, Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe3fc50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhang Xiaoyang\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Zhang Xiaoyang\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load a pretrained model and reset final fully connected layer.\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# retrieve the size of input features produced by the preultimate layer\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "# modifies final fully connect layer (model.fc) to match no. of classes in dataset\n",
    "model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# create an instance of 'CrossEntropyClass', for classification tasks. Measures diff betwn probability distributions of predicted o/p and true labels\n",
    "# citerion is used later on to calculate loss prediction and actual. the lower, the better.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "# SGD updates model parameters using the gradient of the loss with respect to a subset of the data. Makes training faster and can also help model to escape local minima.\n",
    "# smaller learning rate, model updates its parameters more slowly, lead to more precise convergence, require more epoches\n",
    "# momentum is to accelerate SGD optimizer and dampen oscillations\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e475d6",
   "metadata": {},
   "source": [
    "## Training, Validation Function and Training Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16cccde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.6686 Acc: 0.7031\n",
      "val Loss: 0.3567 Acc: 0.8267\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5094 Acc: 0.7568\n",
      "val Loss: 0.3565 Acc: 0.8299\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.4565 Acc: 0.7834\n",
      "val Loss: 0.3294 Acc: 0.8403\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.4304 Acc: 0.7954\n",
      "val Loss: 0.3669 Acc: 0.8195\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.4065 Acc: 0.8101\n",
      "val Loss: 0.2883 Acc: 0.8698\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.3794 Acc: 0.8226\n",
      "val Loss: 0.2975 Acc: 0.8674\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.3775 Acc: 0.8249\n",
      "val Loss: 0.3024 Acc: 0.8618\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.3321 Acc: 0.8467\n",
      "val Loss: 0.2674 Acc: 0.8730\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.3235 Acc: 0.8564\n",
      "val Loss: 0.2702 Acc: 0.8850\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.3104 Acc: 0.8606\n",
      "val Loss: 0.2654 Acc: 0.8778\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.3112 Acc: 0.8559\n",
      "val Loss: 0.2744 Acc: 0.8810\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.2967 Acc: 0.8679\n",
      "val Loss: 0.2627 Acc: 0.8786\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.2966 Acc: 0.8654\n",
      "val Loss: 0.2524 Acc: 0.8898\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.2948 Acc: 0.8669\n",
      "val Loss: 0.2496 Acc: 0.8898\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.2890 Acc: 0.8691\n",
      "val Loss: 0.2576 Acc: 0.8906\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.2833 Acc: 0.8752\n",
      "val Loss: 0.2575 Acc: 0.8906\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.2849 Acc: 0.8724\n",
      "val Loss: 0.2467 Acc: 0.8946\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.2875 Acc: 0.8687\n",
      "val Loss: 0.2518 Acc: 0.8874\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.2873 Acc: 0.8755\n",
      "val Loss: 0.2529 Acc: 0.8898\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.2849 Acc: 0.8691\n",
      "val Loss: 0.2511 Acc: 0.8898\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.2882 Acc: 0.8682\n",
      "val Loss: 0.2455 Acc: 0.8914\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.2827 Acc: 0.8721\n",
      "val Loss: 0.2501 Acc: 0.8962\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.2854 Acc: 0.8701\n",
      "val Loss: 0.2511 Acc: 0.8922\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.2925 Acc: 0.8652\n",
      "val Loss: 0.2461 Acc: 0.8898\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.2846 Acc: 0.8693\n",
      "val Loss: 0.2466 Acc: 0.8954\n",
      "\n",
      "Best val Acc: 0.896166\n"
     ]
    }
   ],
   "source": [
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# Purpose of this is to balance the exploration and exploitation phases of training the model. Initially, main objective is to explore the parameter space broadly, but as you get closer to optimal parameters, you want to fine-tune and exploit promising regions.\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                # Track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "\n",
    "        print()\n",
    "\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# Now we can train the model\n",
    "model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55fd925",
   "metadata": {},
   "source": [
    "## Test Data Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef160ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_dataset = datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "]))\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49277a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure model in eval mode\n",
    "model.eval()\n",
    "\n",
    "#init the predictn and true label lists\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "# Disable gradient computation\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        pred_labels.extend(preds.cpu().numpy())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c268810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.8851\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.sum(np.array(pred_labels) == np.array(true_labels)) / len(true_labels)\n",
    "print(f'Accuracy on the test set: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c594b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94d772c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MEL', 'NV']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(class_names)\n",
    "print(len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6accbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"model_state_dict.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02bb514d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the model state dictionary\n",
    "torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a71e41b",
   "metadata": {},
   "source": [
    "## Running based on Saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16b7e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "289fbfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb101ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'a5_data'  # Or the path to your dataset\n",
    "test_dataset = datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=test_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f54ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e2573fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_state_dict.pth'))\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f956cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cc5ed11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 88.51%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy of the model on the test images: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00960151",
   "metadata": {},
   "source": [
    "## No augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae89465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transformation without data augmentation for training data\n",
    "data_transforms_no_aug = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    # Assuming the validation transforms are already defined correctly\n",
    "    'val': data_transforms['val']  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4be4d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets_no_aug = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms_no_aug[x])\n",
    "                         for x in ['train', 'val']}\n",
    "dataloaders_no_aug = {x: DataLoader(image_datasets_no_aug[x], batch_size=4, shuffle=True, num_workers=4)\n",
    "                      for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7955d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(num_classes, use_pretrained=True):\n",
    "    # Load a pretrained ResNet-18 model\n",
    "    model = models.resnet18(pretrained=use_pretrained)\n",
    "    \n",
    "    # Get the number of input features for the final layer (fully connected layer)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    \n",
    "    # Replace the final fully connected layer with a new one with the correct number of classes\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da3174d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_aug = initialize_model(len(class_names), use_pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d15a5f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_no_aug(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders_no_aug[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                # Track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "\n",
    "        print()\n",
    "\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d9bb78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.8084 Acc: 0.5009\n",
      "val Loss: 0.7603 Acc: 0.5184\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.8078 Acc: 0.4988\n",
      "val Loss: 0.7527 Acc: 0.5272\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.8097 Acc: 0.4961\n",
      "val Loss: 0.7498 Acc: 0.5184\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.8082 Acc: 0.4992\n",
      "val Loss: 0.7898 Acc: 0.5184\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.8095 Acc: 0.4984\n",
      "val Loss: 0.7796 Acc: 0.5056\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.8098 Acc: 0.5003\n",
      "val Loss: 0.7968 Acc: 0.5056\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.8090 Acc: 0.5005\n",
      "val Loss: 0.7789 Acc: 0.5080\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.8077 Acc: 0.4972\n",
      "val Loss: 0.7618 Acc: 0.5288\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.8124 Acc: 0.4967\n",
      "val Loss: 0.7561 Acc: 0.5080\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.8083 Acc: 0.5020\n",
      "val Loss: 0.7722 Acc: 0.5160\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.8084 Acc: 0.4984\n",
      "val Loss: 0.7751 Acc: 0.5144\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.8076 Acc: 0.4944\n",
      "val Loss: 0.7878 Acc: 0.5144\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.8096 Acc: 0.4980\n",
      "val Loss: 0.7882 Acc: 0.5128\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.8091 Acc: 0.5011\n",
      "val Loss: 0.7738 Acc: 0.5152\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.8067 Acc: 0.4983\n",
      "val Loss: 0.7597 Acc: 0.5208\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.8042 Acc: 0.5017\n",
      "val Loss: 0.7615 Acc: 0.5160\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.8090 Acc: 0.5026\n",
      "val Loss: 0.7673 Acc: 0.5192\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.8088 Acc: 0.5012\n",
      "val Loss: 0.7637 Acc: 0.5136\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.8051 Acc: 0.5020\n",
      "val Loss: 0.7856 Acc: 0.5128\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.8061 Acc: 0.5025\n",
      "val Loss: 0.7588 Acc: 0.5096\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.8084 Acc: 0.5017\n",
      "val Loss: 0.7958 Acc: 0.5072\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.8143 Acc: 0.4930\n",
      "val Loss: 0.7881 Acc: 0.5184\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.8098 Acc: 0.4981\n",
      "val Loss: 0.7889 Acc: 0.5072\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.8064 Acc: 0.5005\n",
      "val Loss: 0.8053 Acc: 0.5008\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.8131 Acc: 0.4977\n",
      "val Loss: 0.7773 Acc: 0.5192\n",
      "\n",
      "Best val Acc: 0.528754\n"
     ]
    }
   ],
   "source": [
    "# Assuming loss criterion, optimizer, and scheduler setup are done\n",
    "model_ft_no_aug = train_model_no_aug(model_without_aug, criterion, optimizer, exp_lr_scheduler, num_epochs=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f3df7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():  # Inference mode, gradients not needed\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            _, predictions = torch.max(outputs, 1)  # Get the index of the max log-probability as the prediction\n",
    "            \n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33cbb7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5065885797950219"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model_ft_no_aug, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bc7458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_NO_AUG = \"model_state_dict_no_aug.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11c0a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model state dictionary\n",
    "torch.save(model_without_aug.state_dict(), PATH_NO_AUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bc71eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
